# Travel Plan Generation Flow

## Architecture Overview

```
Mobile App / Web Browser
        â†“
   API Gateway (8080)
        â†“
   Plan Service (8083) - Java Spring Boot
        â†“ HTTP REST Call
   LLM Agent (8000) - Python FastAPI
        â†“ Uses prompts from
   prompts/system_prompts.yaml
        â†“ Calls
   AWS Bedrock - Claude Sonnet 3.5
```

## Components

### 1. Plan Service (Java)
**Location:** `/services/plan-service/`
**Port:** 8083
**Role:** API endpoint handler, calls Python LLM service

**Key File:** `src/main/java/com/oddiya/plan/service/PlanService.java`

```java
public Mono<PlanResponse> createPlan(Long userId, CreatePlanRequest request) {
    // 1. Generate title from destination
    String title = generateTitle(request.getDestination(), ...);

    // 2. Build request for Python LLM service
    LlmRequest llmRequest = new LlmRequest();
    llmRequest.setTitle(title);
    llmRequest.setLocation(request.getDestination());
    llmRequest.setStartDate(request.getStartDate().toString());
    llmRequest.setEndDate(request.getEndDate().toString());
    llmRequest.setBudget(determineBudgetLevel(request.getBudget()));

    // 3. Call Python LLM Agent
    return llmAgentClient.generatePlan(llmRequest)
        .map(llmResponse -> {
            // 4. Return plan directly WITHOUT saving to database
            PlanResponse response = new PlanResponse();
            // ... map fields from llmResponse
            return response;
        });
}
```

**Important:**
- âŒ **Does NOT save to database**
- âœ… **Returns plan directly** from Python service
- âœ… **Stateless** - no persistence

### 2. LLM Agent (Python)
**Location:** `/services/llm-agent/`
**Port:** 8000
**Role:** AI travel plan generation using Claude Sonnet

**Key Files:**
- `main.py` - FastAPI application
- `src/routes/langgraph_plans.py` - Plan generation endpoint
- `src/services/langgraph_planner.py` - LangGraph workflow

**API Endpoint:**
```
POST http://localhost:8000/api/v1/plans/generate
Content-Type: application/json

{
    "title": "Seoul 3-Day Adventure",
    "location": "Seoul",
    "startDate": "2025-12-01",
    "endDate": "2025-12-03",
    "budget": "medium"
}
```

### 3. Prompt Management
**Location:** `/services/llm-agent/prompts/system_prompts.yaml`

**âœ… Prompts are managed separately from code!**

```yaml
system_message: |
  ë‹¹ì‹ ì€ í•œêµ­ ì—¬í–‰ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤.
  ì‚¬ìš©ìžì—ê²Œ ì‹¤ìš©ì ì´ê³  í˜„ì‹¤ì ì¸ ì—¬í–‰ ê³„íšì„ ì œê³µí•©ë‹ˆë‹¤.

  ì›ì¹™:
  - ì‹¤ì œ ì¡´ìž¬í•˜ëŠ” ê´€ê´‘ì§€ì™€ ìž¥ì†Œë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤
  - ì˜ˆì‚°ì— ë§žëŠ” í™œë™ì„ ì œì•ˆí•©ë‹ˆë‹¤
  - ë‚ ì”¨ë¥¼ ê³ ë ¤í•œ ì¼ì •ì„ ì§­ë‹ˆë‹¤

planning_prompt_template: |
  "{location}" ì§€ì—­ì˜ {num_days}ì¼ ì—¬í–‰ ê³„íšì„ ìƒì„±í•´ì£¼ì„¸ìš”.

  ì—¬í–‰ ì •ë³´:
  - ì œëª©: {title}
  - ì¼ì •: {start_date} ~ {end_date}
  - ì˜ˆì‚° ìˆ˜ì¤€: {budget_level}

  ìš”êµ¬ì‚¬í•­:
  1. ì •í™•ížˆ {num_days}ì¼ì˜ ì¼ì •ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”
  2. {location}ì˜ ì‹¤ì œ ì¡´ìž¬í•˜ëŠ” ê´€ê´‘ì§€, ì‹ë‹¹, ì¹´íŽ˜ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œí•˜ì„¸ìš”
  3. ê° í™œë™ë§ˆë‹¤ êµ¬ì²´ì ì¸ ì‹œê°„ì„ ëª…ì‹œí•˜ì„¸ìš”
  ...
```

**To Update Prompts:**
1. Edit `/services/llm-agent/prompts/system_prompts.yaml`
2. Restart LLM Agent: `lsof -ti:8000 | xargs kill; cd services/llm-agent && python main.py`
3. âœ… **No code changes needed!**

## Request Flow

### 1. User Creates Plan (Web/Mobile)
```javascript
// Web UI: index.html
const planRequest = {
    destination: "Seoul",
    startDate: "2025-12-01",
    endDate: "2025-12-03",
    budget: 500000,
    interests: ["food", "culture"]
};

fetch('http://localhost:8080/api/v1/plans', {
    method: 'POST',
    headers: {
        'Authorization': 'Bearer ' + accessToken,
        'Content-Type': 'application/json'
    },
    body: JSON.stringify(planRequest)
});
```

### 2. API Gateway Routes Request
```yaml
# services/api-gateway/src/main/resources/application.yml
routes:
  - id: plan-service
    uri: http://localhost:8083
    predicates:
      - Path=/api/v1/plans/**
```

### 3. Plan Service Calls Python LLM Agent
```java
// Plan Service
llmAgentClient.generatePlan(llmRequest)
    .map(llmResponse -> convertToResponse(llmResponse));
```

**HTTP Request:**
```http
POST http://localhost:8000/api/v1/plans/generate
Content-Type: application/json

{
    "title": "Seoul 3-Day Trip",
    "location": "Seoul",
    "startDate": "2025-12-01",
    "endDate": "2025-12-03",
    "budget": "medium",
    "maxIterations": 3
}
```

### 4. Python LLM Agent Processing
```python
# src/services/langgraph_planner.py
async def generate_plan(self, title, location, start_date, end_date, budget):
    # 1. Load prompts from system_prompts.yaml
    system_message = prompt_loader.get_system_message()
    planning_prompt = prompt_loader.get_planning_prompt(...)

    # 2. Call AWS Bedrock Claude Sonnet 3.5
    response = bedrock.invoke_model(
        modelId="anthropic.claude-3-5-sonnet-20241022-v2:0",
        body={
            "messages": [
                {"role": "system", "content": system_message},
                {"role": "user", "content": planning_prompt}
            ]
        }
    )

    # 3. Parse and validate response
    plan = parse_json_response(response)

    # 4. Return structured plan
    return {
        "title": "Seoul 3-Day Adventure",
        "days": [
            {
                "day": 1,
                "location": "ê²½ë³µê¶ & ë¶ì´Œí•œì˜¥ë§ˆì„",
                "activity": "Morning: ê²½ë³µê¶ (â‚©3,000), Afternoon: ë¶ì´Œí•œì˜¥ë§ˆì„ (ë¬´ë£Œ)...",
                "estimatedCost": 50000
            },
            ...
        ]
    }
```

### 5. Response Returns to User
```json
{
    "userId": 1,
    "title": "Seoul 3-Day Adventure",
    "startDate": "2025-12-01",
    "endDate": "2025-12-03",
    "details": [
        {
            "day": 1,
            "location": "ê²½ë³µê¶ & ë¶ì´Œí•œì˜¥ë§ˆì„",
            "activity": "Morning: ê²½ë³µê¶ (â‚©3,000), Afternoon: ë¶ì´Œí•œì˜¥ë§ˆì„ (ë¬´ë£Œ), Evening: ëª…ë™êµìž (â‚©15,000)"
        }
    ],
    "createdAt": "2025-11-03T19:46:00",
    "updatedAt": "2025-11-03T19:46:00"
}
```

## How to Manage Prompts

### 1. View Current Prompts
```bash
cat /Users/wjs/cursor/oddiya/services/llm-agent/prompts/system_prompts.yaml
```

### 2. Edit Prompts
```bash
# Open in editor
vi /Users/wjs/cursor/oddiya/services/llm-agent/prompts/system_prompts.yaml

# Or use any text editor
open /Users/wjs/cursor/oddiya/services/llm-agent/prompts/system_prompts.yaml
```

### 3. Available Prompt Templates

**system_message:**
- Defines the AI's role and principles
- Example: "ë‹¹ì‹ ì€ í•œêµ­ ì—¬í–‰ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤."

**planning_prompt_template:**
- Main prompt for generating travel plans
- Variables: `{location}`, `{num_days}`, `{title}`, `{budget_level}`
- Includes output format requirements

**refinement_prompt_template:**
- Used when iteratively improving plans
- Takes feedback and generates improved version

**validation_criteria:**
- Rules for validating generated plans
- Budget limits, day count, weather considerations

### 4. Restart Services After Prompt Changes
```bash
# Kill and restart LLM Agent
lsof -ti:8000 | xargs kill -9
cd /Users/wjs/cursor/oddiya/services/llm-agent
python main.py > /tmp/llm-agent.log 2>&1 &

# Plan Service doesn't need restart (it calls Python service)
```

## Testing the Flow

### 1. Check Services Are Running
```bash
# API Gateway (8080)
curl http://localhost:8080/actuator/health

# Plan Service (8083)
curl http://localhost:8083/actuator/health

# LLM Agent (8000)
curl http://localhost:8000/health
```

### 2. Test Plan Generation Directly (Python Service)
```bash
curl -X POST http://localhost:8000/api/v1/plans/generate \
  -H "Content-Type: application/json" \
  -d '{
    "title": "Seoul 3-Day Trip",
    "location": "Seoul",
    "startDate": "2025-12-01",
    "endDate": "2025-12-03",
    "budget": "medium"
  }'
```

### 3. Test Full Flow (Through Java Service)
```bash
curl -X POST http://localhost:8083/api/v1/plans \
  -H "Content-Type: application/json" \
  -H "X-User-Id: 1" \
  -d '{
    "destination": "Seoul",
    "startDate": "2025-12-01",
    "endDate": "2025-12-03",
    "budget": 500000,
    "interests": ["food", "culture"]
  }'
```

## Important Notes

### âœ… What's Working
- Java Plan Service calls Python LLM Agent via HTTP REST
- Prompts are managed in `prompts/system_prompts.yaml`
- Plans are generated by Claude Sonnet 3.5 via AWS Bedrock
- **Plans are NOT saved to database** (stateless)
- Full authentication flow with JWT tokens

### âš ï¸ Current Limitations
- No database persistence (by design for now)
- User cannot view previously generated plans
- Each request generates a new plan (no caching)

### ðŸ”§ Future Enhancements
When you want to add database persistence:
1. Remove `@Transactional` comment in `PlanService.createPlan()`
2. Add back `planRepository.save(plan)` call
3. Update `getUserPlans()` to fetch from database

## Troubleshooting

### Python Service Not Responding
```bash
# Check if running
lsof -ti:8000

# Check logs
tail -f /tmp/llm-agent.log

# Restart
cd /Users/wjs/cursor/oddiya/services/llm-agent
python main.py > /tmp/llm-agent.log 2>&1 &
```

### Java Service Can't Connect to Python
```bash
# Verify URL in application.yml
cat /Users/wjs/cursor/oddiya/services/plan-service/src/main/resources/application.yml | grep -A 5 "llm:"

# Should show:
# llm:
#   agent:
#     base-url: ${LLM_AGENT_URL:http://localhost:8000}
```

### AWS Bedrock Authentication Issues
```bash
# Check AWS credentials
aws sts get-caller-identity

# Verify Bedrock model access
aws bedrock list-foundation-models --region us-east-1
```
